- 为什么需要机器学习

  - 数据：观测值和测量值
  - 数据分析：对数据的加工处理
  - 信息：可信数据
  - 数据挖掘：机器学习
  - 有价值信息

- 机器学习和大数据联系
  - 流程
    - ![image](https://user-images.githubusercontent.com/27959851/114643024-79479b80-9d07-11eb-8782-05fa48b1d508.png)
    - 首先判断任务是否是机器学习任务
    - 根据数据集是否有标签列，有标签列可以用监督学习的分类或者回归
    - 确定好是分类还是回归问题
    - 特征工程80%(数值化，特征向量化，归一化，卡方校验)，利用数据+算法构建模型，根据训练好的模型进行预测
    - 没有标签列，通过聚类算法实现间接分类，继续完成特征工程

  - 大数据
    - 数据存储+统计
  - 机器学习
    - 根据提供数据结合算法构建模型，通过模型实现对现实事件预测
  - 预测明天是否下雨（是 否） 
    - 采样以往十五年同期数据+机器学习分类算法(决策树)=预测是否下雨模型
    - cpu+gpu+数据=模型(经验)
  - 怎么算机器学习
    - 是否有预测过程，已经有确定性的不是，统计的不是
    - 基于规则学习和基于模型的学习
    - 特征，属性+模型=预测结果，或标签结果
      - 基于模型学习：训练集，测试集，得出k和b等参数
  - - 
  - 人工智能>机器学习>深度学习
    - 模式识别
    - 机器学习。可以解决推理，挖掘相关的
    - 深度学习解决机器学习某些方面不足，
  - 热门方向
    - 图像识别，分类
    - 无人驾驶，强化学习
    - 翻译，
    - 语音识别
    - 医疗诊断
    - 数据挖掘
  - 理论化=>模型化=>程序化
  - 跳棋(专家系统)，象棋(统计模型)，围棋(大数据神经网络)
  - x特征+y标签列=>机器学习算法 =>机器学习模型
  - 我们会把mysql中一个记录称为机器学习中的样本。提供特殊方法将记录中内容量化，
    - labelencoder
      - 如青年中年老年转为0，1，2
    - onehotencoder
      - ![image-20210411161405853](/var/folders/cd/l2s3phgd211gxcmxgkghvk3m0000gn/T/abnerworks.Typora/image-20210411161405853.png)
  - 训练集和测试集
    - 训练集通过特征向量计算出的结果模型与测试数据集进行运算
      - 如：绝对误差值，方差等得出一个误差较小的模型
  - 误差类型
    - 训练误差
    - 测试误差
    - 泛化误差
  - 机器学习就是搞向量
    - 稀疏矩阵
    - 稠密矩阵

- 监督学习(任务驱动)

  - 结果标签列已知，
  - 离散：分类问题 
  - 连续：回归问题，房价范围问题
  - 标注问题（特殊的）：词性标注，隐马尔可夫模型

- 无监督学习(数据驱动)

  - 没有标签
  - 将相似的人群聚集在一起，特征向量相似性，
    - 降维：主成分分析法，因子分析法
      - 和特征选择
      - 降维：高纬度降到低维度，低维度仍可分类
    - 聚类

- 半监督学习，互联网常见

  - 主动学习：找专家来一个个打标签，有专家的主观因素不一定适合
  - 法一：
    - 半监督学习中部分有标签，将有标签的内容，先把特征干掉，再和未标签数据进行合并后采用无监督学习的聚类，分类完后根据有标签的数量少数服从多数方法，将标签结果选择出来，给所有属于该组的没有标签的数据加上这个标签

- 强化学习

  - 解决连续决策问题，无人驾驶

- 迁移学习

  - 数据量大的场景。和相关联数据量小的场景，可以现在数据量大的场景下建立模型，再迁移到小数据量场景中

- 深度学习

  - 利用模拟神经网络结构构建
  - 解决图像，人脸，语音识别等特征提取问题

- 构建机器学习模型

  - 方法1:数据+算法+策略

  - 方法2:模型+策略+算法

  - 内容

    - 模型：y=kx+b

      - 决策函数，直接得出是好是坏
      - 条件概率分布函数，百分比是好百分比多少是坏

    - 策略：误差函数=损失函数

      - 0-1损失，对离散型预测对错，分类问题
      - 平房损失函数 回归问题

    - 算法：最优参数找出来的方法

      - 二分法
      - 梯度下降
      - 牛顿法

- 如何评价呢（模型泛化能力评估，奥卡姆剃刀原则，尽量选择简单模型，容易防止过拟合）

  - 欠拟合
    - 模型在训练集，测试集都很差，平时考试，和高考都很差
    - 在模型训练初期，模型太简单，增加多项式的项，重新清洗数据，采样数据
  - 过拟合
    - 训练集效果好，测试集效果差，平时考很好，高考很烂

  ![image-20210411175035394](/var/folders/cd/l2s3phgd211gxcmxgkghvk3m0000gn/T/abnerworks.Typora/image-20210411175035394.png)

  - 正则化，简化损失函数

    - L1正则
      - 加个一次项
    - L2正则
      - 加个二次型

- 经验风险和结构风险

  - 经验风险基于随机变量的数学期望，也称为平均损失，当n趋近于无穷经验风险趋近于期望风险
  - 但是经验风险下降是会可能导致训练错误率减少最终发生过拟合，需要配合结构风险处理（配合正则化处理）

- 交叉验证

  - 简单交叉验证
    - 拆分为训练集和测试集
    - 训练模型
  - k则交叉验证
    - 10则交叉验证，将数据集随机平均切分为10等分，获取其中一份数据作为测试集，其余做训练集，可以训练出10个模型，平均损失
    - 用于超参数验证
- 网格验证
## sparkmllib

- guide（五大特征）
  - ml算法：分类(监督)，回归(监督)，聚类(非监督)，降维，协同过滤
  - featurization特征工程：特征抽取（主要是为图片和文本等非结构化数据处理），transformation（encoder）(非数值化转化，归一化转化),dimensionality reduction 降维， selecttion 特征选择
  - pipelines管道，各算法融合
  - persistence持久化，保存模型
  - utilities工具，线性代数统计学
- 两种api,rdd和dataframe.dataframe是主要的api,过去有spark.ml是基于rdd的代码冗余，现在用mllib基于df
  - df可以用pipeline加快计算,datasource，sql查询，tusten,catalyst,多语言支持
  - ![image](https://user-images.githubusercontent.com/27959851/114333045-0361f980-9b7a-11eb-8d37-100670bbac1c.png)
- spark架构
  - netlib-java数值运算
  - breeze 矩阵运算
  - vector 向量接口
  - matrix 矩阵接口
- usg中重要算法包括随机森林，线性回归，聚类算法
- sparkMLlib 数据结构
  - 向量
  - 矩阵
- sparkmllib 特征工程构建过程
  - 提取特征，文本图像数据抽取
  - 选择：从更大特征集中选1-2个特征
  - 转换，缩放，转换修改特征
    - 离散值，非数值型
      - StringIndexer:从string类型转为indexer类型，非数值转为数值
        - 根据出现数值的次数编排索引，出现数值多的索引靠前
      - IndexerToString: 从数值类型映射为string
      - onehotencoder： 独热编码 -001 010 100，默认会把最后一列干掉，作为稀疏矩阵存储节省空间
    - 连续值
      - binarizer二值化， 
      - bucketizer 分箱操作  
      - quanttileDiscreater 分位数转换
    - 特征组合
      - vectorassembler 特征向量集成
        - 离散特征值转为特征向量
        - ******************
      - vectorIndexer 特征转下标
      - labelPoint
        - libsvm******稀疏矩阵支撑向量机 , 每个特征值都会打上标签 结构为=>  标签index: 归一化值
        - ``` MLUtils.loadLibSVMFile(sc,"data/")
    - 数值型：标准化(变为标准正态分布，加快收敛，减少拟合误差)，归一化(去量纲)
      - standscaler 标准化  - 均值/方差
      - minmaxscaler 数值型数据的归一化，减去最大值除最大值减最小值 归一化到0-1之间
        - 归一化，是针对一列进行的
      - maxAbsScaler 归一化  一列具体的取值/绝对的最大值。
  - 如何选择特征
    - 卡方检验输入需要选取特征数，通过计算判断哪几列跟我们的label相关，
    - ``` new ChiSqSelector().setFeaturesCol("").setLabelCol("").setNUmTopFeatures(2).setoutputFeaturesCol
- 决策树
  - 叶子节点过多会导致过拟合
  - 场景：
    - 根据年龄收入角色信誉判断是否购买
    - 根据规则判断
    - 根据id3,c4.5,cart树判断
      - 信息熵 香农，表示信息分布均匀程度，所以我们需要找到一个数据分布的分割位置，可以用于信息的分类，要找一个信息熵小的，有助于得出更多细分
        - h = -sum(pi*log(pi))
      - id3:输入数据集，输出决策树。选择属性判断节点，建立决策树，引入信息增益，获取信息量
        - a特征的信息增益= 总体的信息熵-以a节点作为分支节点信息熵
        - 信息增益可以用来衡量可否更加好的切分训练数据集
      - c4.5 根据信息熵增益率解决取值较多的不足，譬如不小心把主键id作为了分类可以避免
      - cart tree 通过gini系数，分类和回归树
  - 决策树的剪枝
    - 防止过拟合
    - 先剪枝
      - 提前结束决策树增长，限制树高，但是受到主观性影响
      - 指定超参数（训练之前事先指定的参数）
    - 后剪枝
      - 生长完毕后再减，要考虑提供替换节点的容错性，mep最小错误率剪枝技术，选择剪枝一定不能让错误率上升过快
  - 参数处理，算法选择，不纯度
    - 参数是
      - 连续的要处理为离散，分类的要处理
      - 深度控制
    - 不纯度：geni基尼, entropy信息熵
- 评估模型
  - 真正率，假正率，精确率，准确率，ROC（受试者工作曲线），AUC（二分类曲线下面积[](url)）
  - ![image](https://user-images.githubusercontent.com/27959851/114652953-8a99a380-9d19-11eb-99de-660957079c50.png)
  - 交叉验证 CrossValidator
  - 网格验证 ParamGridBuilder
- 什么时候用fit什么时候用transform
  - 继承自transform可以直接transform，继承自estimator要先fit再transform
- USG模型引入
  - 什么是USG模型
    - user shopping gender ,用户在一段时间内购买商品的数量来判断用户的性别是男还是女
  - 如何实现USG
  - 实际意义和价值
